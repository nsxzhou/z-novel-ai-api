# z-novel-ai-api AI æ¨¡å—å…¨æ™¯æ¢³ç†

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æ›´æ–°æ—¶é—´**: 2026-01-07  
**é€‚ç”¨èŒƒå›´**: å¼€å‘è€…ã€æ¶æ„å¸ˆã€è¿ç»´äººå‘˜

---

## ğŸ“‹ ç›®å½•

- [1. æ¨¡å—æ¦‚è¿°](#1-æ¨¡å—æ¦‚è¿°)
- [2. æ•´ä½“æ¶æ„](#2-æ•´ä½“æ¶æ„)
- [3. æ ¸å¿ƒç»„ä»¶è¯¦è§£](#3-æ ¸å¿ƒç»„ä»¶è¯¦è§£)
  - [3.1 åŸºç¡€è®¾æ–½å±‚](#31-åŸºç¡€è®¾æ–½å±‚)
  - [3.2 å·¥ä½œæµç¼–æ’å±‚](#32-å·¥ä½œæµç¼–æ’å±‚)
  - [3.3 åº”ç”¨å±‚](#33-åº”ç”¨å±‚)
  - [3.4 å¯è§‚æµ‹æ€§å±‚](#34-å¯è§‚æµ‹æ€§å±‚)
- [4. ä¸‰å¤§ AI ç”Ÿæˆå™¨](#4-ä¸‰å¤§aiç”Ÿæˆå™¨)
- [5. æ•°æ®æµå‘ä¸è°ƒç”¨é“¾](#5-æ•°æ®æµå‘ä¸è°ƒç”¨é“¾)
- [6. HTTP API æ¥å£](#6-http-apiæ¥å£)
- [7. é…ç½®ä¸éƒ¨ç½²](#7-é…ç½®ä¸éƒ¨ç½²)
- [8. æœªæ¥è§„åˆ’](#8-æœªæ¥è§„åˆ’)

---

## 1. æ¨¡å—æ¦‚è¿°

`z-novel-ai-api`çš„ AI æ¨¡å—æ˜¯æ•´ä¸ªå°è¯´åˆ›ä½œç³»ç»Ÿçš„æ ¸å¿ƒå¼•æ“,è´Ÿè´£å°†ç”¨æˆ·çš„åˆ›ä½œæ„å›¾è½¬åŒ–ä¸ºå…·ä½“çš„å°è¯´è®¾å®šå†…å®¹ã€‚è¯¥æ¨¡å—åŸºäºå­—èŠ‚è·³åŠ¨çš„**Eino æ¡†æ¶**æ„å»º,æä¾›äº†ä»é¡¹ç›®å­µåŒ–åˆ°è®¾å®šè¿­ä»£çš„å®Œæ•´ AI è¾…åŠ©åˆ›ä½œèƒ½åŠ›ã€‚

### 1.1 æ ¸å¿ƒèƒ½åŠ›

| èƒ½åŠ›           | æè¿°                                                                   | çŠ¶æ€        |
| -------------- | ---------------------------------------------------------------------- | ----------- |
| **é¡¹ç›®å­µåŒ–**   | é€šè¿‡ 4 é˜¶æ®µå¯¹è¯(discoverâ†’narrowâ†’draftâ†’confirm)å°†æ¨¡ç³Šæƒ³æ³•è½¬åŒ–ä¸ºæ­£å¼é¡¹ç›® | âœ… å·²å®Œæˆ   |
| **è®¾å®šè¿­ä»£**   | åœ¨å·²æœ‰é¡¹ç›®ä¸Šé€šè¿‡å¤šè½®å¯¹è¯åå¤æ‰“ç£¨è®¾å®š(ä¸–ç•Œè§‚/è§’è‰²/å¤§çº²)                 | âœ… å·²å®Œæˆ   |
| **ä¸€æ½å­ç”Ÿæˆ** | ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´è®¾å®šåŒ…(Foundation),é€‚åˆé¡¹ç›®å†·å¯åŠ¨                        | âœ… å·²å®Œæˆ   |
| **ç« èŠ‚ç”Ÿæˆ**   | åŸºäºå¤§çº²ä¸ä¸Šä¸‹æ–‡ç”Ÿæˆç« èŠ‚æ­£æ–‡                                           | â³ å ä½å®ç° |
| **å‘é‡æ£€ç´¢**   | RAG æ£€ç´¢ä¸ä¸Šä¸‹æ–‡å¬å›                                                   | â³ å ä½å®ç° |

### 1.2 æŠ€æœ¯æ ˆ

- **ç¼–æ’æ¡†æ¶**: Cloudwego Eino (Chain / Graph / Tool Calling / Callbacks)
- **LLM æä¾›å•†**: æ”¯æŒ OpenAI æ ¼å¼çš„å¤š Provider åˆ‡æ¢(OpenAIã€DeepSeek ç­‰)
- **å‘é‡æ•°æ®åº“**: Milvus (è§„åˆ’ä¸­)
- **å¯è§‚æµ‹æ€§**: OpenTelemetry (Tracing) + Prometheus (Metrics)

---

## 2. æ•´ä½“æ¶æ„

### 2.1 åˆ†å±‚æ¶æ„å›¾

```mermaid
flowchart TB
    subgraph HTTP["HTTPå±‚ (interfaces/http)"]
        Handler1["project_creation.go<br/>é¡¹ç›®å­µåŒ–Handler"]
        Handler2["conversation.go<br/>é•¿æœŸä¼šè¯Handler"]
        Handler3["foundation.go<br/>Foundation Handler"]
        Handler4["artifact.go<br/>æ„ä»¶ç‰ˆæœ¬Handler"]
    end

    subgraph APP["åº”ç”¨å±‚ (application/story)"]
        Gen1["ProjectCreationGenerator<br/>å­µåŒ–ç”Ÿæˆå™¨(Chain)"]
        Gen2["ArtifactGenerator<br/>è®¾å®šç”Ÿæˆå™¨(Graph+Tools)"]
        Gen3["FoundationGenerator<br/>Foundationç”Ÿæˆå™¨(Chain)"]
    end

    subgraph WF["å·¥ä½œæµå±‚ (workflow)"]
        Prompt["PromptRegistry<br/>Promptæ¨¡æ¿ç®¡ç†(go:embed)"]
        Templates["templates/*.txt<br/>ChatTemplateæ–‡ä»¶"]
    end

    subgraph INFRA["åŸºç¡€è®¾æ–½å±‚ (infrastructure)"]
        LLM["EinoFactory<br/>LLMå·¥å‚(å¤šProvider)"]
        Embed["EinoEmbedder<br/>å‘é‡åŒ–å®¢æˆ·ç«¯"]
    end

    subgraph OBS["å¯è§‚æµ‹æ€§å±‚ (observability/eino)"]
        Callback["GlobalCallbacks<br/>LLM/Toolè°ƒç”¨ç›‘æ§"]
        Metrics["PrometheusæŒ‡æ ‡<br/>(Token/Latency/Calls)"]
    end

    Handler1 --> Gen1
    Handler2 --> Gen2
    Handler3 --> Gen3
    Handler4 --> Gen2

    Gen1 --> Prompt
    Gen2 --> Prompt
    Gen3 --> Prompt

    Gen1 --> LLM
    Gen2 --> LLM
    Gen3 --> LLM

    Prompt --> Templates

    LLM --> Callback
    Callback --> Metrics

    style HTTP fill:#e1f5ff
    style APP fill:#fff4e1
    style WF fill:#f0e1ff
    style INFRA fill:#e1ffe1
    style OBS fill:#ffe1e1
```

### 2.2 æ•°æ®æµå‘

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Handler as HTTP Handler
    participant Generator as AIç”Ÿæˆå™¨
    participant Prompt as PromptRegistry
    participant LLM as EinoFactory
    participant Model as OpenAIå…¼å®¹æ¨¡å‹
    participant Callback as å¯è§‚æµ‹æ€§

    User->>Handler: å‘é€åˆ›ä½œè¯·æ±‚
    Handler->>Generator: è°ƒç”¨Generate(input)
    Generator->>Prompt: è·å–ChatTemplate
    Prompt-->>Generator: è¿”å›æ¨¡æ¿
    Generator->>Generator: æ„å»ºMessages
    Generator->>LLM: Get(provider)
    LLM-->>Generator: ChatModelå®ä¾‹
    Generator->>Model: Generate(messages, options)
    Model-->>Callback: OnStart(å¼€å§‹ç›‘æ§)
    Model-->>Generator: è¿”å›ç”Ÿæˆç»“æœ
    Model-->>Callback: OnEnd(è®°å½•æŒ‡æ ‡)
    Generator->>Generator: Parse+Validate
    Generator-->>Handler: è¿”å›æ ‡å‡†åŒ–è¾“å‡º
    Handler-->>User: è¿”å›HTTPå“åº”
```

---

## 3. æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 3.1 åŸºç¡€è®¾æ–½å±‚

#### 3.1.1 LLM å·¥å‚ (`internal/infrastructure/llm/eino_factory.go`)

**èŒè´£**:ç®¡ç†å¤šä¸ª LLM Provider çš„å®¢æˆ·ç«¯å®ä¾‹,æä¾›ç»Ÿä¸€è®¿é—®æ¥å£ã€‚

**æ ¸å¿ƒæ–¹æ³•**:

```go
type EinoFactory struct {
    config *config.LLMConfig
    models map[string]model.BaseChatModel  // Provideråç§° -> ChatModelå®ä¾‹
}

// è·å–æŒ‡å®šProviderçš„ChatModel,æ”¯æŒæƒ°æ€§åŠ è½½
func (f *EinoFactory) Get(ctx context.Context, name string) (model.BaseChatModel, error)

// è·å–é»˜è®¤Provider
func (f *EinoFactory) Default(ctx context.Context) (model.BaseChatModel, error)
```

**ç‰¹æ€§**:

- âœ… æ”¯æŒå¤š Provider é…ç½®(OpenAIã€DeepSeek ç­‰ OpenAI å…¼å®¹æ ¼å¼)
- âœ… æƒ°æ€§åŠ è½½+å¹¶å‘å®‰å…¨(sync.RWMutex)
- âœ… åŸºäº Eino çš„`openai.NewChatModel`é€‚é…å™¨

**é…ç½®ç¤ºä¾‹**:

```yaml
llm:
  default_provider: "openai"
  providers:
    openai:
      api_key: "sk-xxx"
      base_url: "https://api.openai.com/v1"
      model: "gpt-4o"
      max_tokens: 8000
      temperature: 0.7
    deepseek:
      api_key: "sk-yyy"
      base_url: "https://api.deepseek.com/v1"
      model: "deepseek-chat"
```

#### 3.1.2 å‘é‡åŒ–å®¢æˆ·ç«¯ (`internal/infrastructure/embedding/eino_client.go`)

**èŒè´£**:æä¾› Embedding å‘é‡åŒ–èƒ½åŠ›(ç”¨äºåç»­ RAG æ£€ç´¢)ã€‚

**å½“å‰çŠ¶æ€**:åŸºç¡€å®ç°å·²å®Œæˆ,ä½†å‘é‡æ£€ç´¢æœåŠ¡ä»ä¸ºå ä½å®ç°ã€‚

---

### 3.2 å·¥ä½œæµç¼–æ’å±‚

#### 3.2.1 Prompt ç®¡ç† (`internal/workflow/prompt/`)

**è®¾è®¡ç†å¿µ**:

- **ç»Ÿä¸€ç®¡ç†**:æ‰€æœ‰ Prompt æ¨¡æ¿é›†ä¸­å­˜å‚¨åœ¨`templates/*.txt`
- **ç‰ˆæœ¬åŒ–**:é€šè¿‡`go:embed`å†…åµŒåˆ°äºŒè¿›åˆ¶,é¿å…è¿è¡Œæ—¶æ–‡ä»¶ä¾èµ–
- **å¯å¤ç”¨**:é€šè¿‡ PromptRegistry æŒ‰ ID è·å–æ¨¡æ¿

**ç›®å½•ç»“æ„**:

```
internal/workflow/prompt/
â”œâ”€â”€ registry.go              # Promptæ³¨å†Œä¸è·å–
â””â”€â”€ templates/               # Promptæ¨¡æ¿æ–‡ä»¶
    â”œâ”€â”€ foundation_v1.txt    # Foundationç”Ÿæˆæ¨¡æ¿
    â”œâ”€â”€ artifact_v1.txt      # Artifactç”Ÿæˆæ¨¡æ¿
    â”œâ”€â”€ project_creation_v1.txt  # é¡¹ç›®å­µåŒ–æ¨¡æ¿
    â””â”€â”€ ...
```

**æ ¸å¿ƒä»£ç **:

```go
//go:embed templates/*.txt
var templateFS embed.FS

type PromptRegistry struct {
    templates map[string]string  // PromptID -> æ¨¡æ¿å†…å®¹
}

// æ ¹æ®PromptIDè·å–ChatTemplate
func (r *PromptRegistry) ChatTemplate(id string) (*prompt.ChatTemplate, error)
```

---

### 3.3 åº”ç”¨å±‚

åº”ç”¨å±‚åŒ…å«ä¸‰å¤§ AI ç”Ÿæˆå™¨,åˆ†åˆ«å¯¹åº”ä¸åŒçš„åˆ›ä½œåœºæ™¯ã€‚æ‰€æœ‰ç”Ÿæˆå™¨å‡å¤ç”¨`EinoFactory`ä½œä¸º LLM å®¢æˆ·ç«¯ã€‚

#### 3.3.1 é€šç”¨æ¶æ„æ¨¡å¼

```mermaid
flowchart LR
    Input([è¾“å…¥]) --> Template[ChatTemplateæ ¼å¼åŒ–]
    Template --> Model[LLM Generate]
    Model --> Parse[JSONè§£æ]
    Parse --> Validate[ä¸šåŠ¡æ ¡éªŒ]
    Validate --> Output([è¾“å‡º])

    Model -.é™çº§.-> Fallback[å¤‡ç”¨Provider]
    Validate -.å¤±è´¥.-> Repair[ä¿®å¤ç­–ç•¥]
```

---

### 3.4 å¯è§‚æµ‹æ€§å±‚

#### 3.4.1 Eino Callbacks (`internal/observability/eino/`)

**èŒè´£**:é€šè¿‡ Eino çš„å…¨å±€å›è°ƒæœºåˆ¶,åœ¨ LLM å’Œ Tool è°ƒç”¨æ—¶è‡ªåŠ¨é‡‡é›†æŒ‡æ ‡ã€‚

**æ ¸å¿ƒç›‘æ§ç‚¹**:

| ç±»å‹          | ç›‘æ§é¡¹     | Prometheus æŒ‡æ ‡                                           |
| ------------- | ---------- | --------------------------------------------------------- |
| **LLM è°ƒç”¨**  | è°ƒç”¨æ¬¡æ•°   | `llm_requests_total{workflow,provider,model,status}`      |
|               | è°ƒç”¨è€—æ—¶   | `llm_latency_seconds{workflow,provider,model}`            |
|               | Token æ¶ˆè€— | `llm_tokens_total{provider,model,type=prompt/completion}` |
| **Tool è°ƒç”¨** | è°ƒç”¨æ¬¡æ•°   | `tool_calls_total{workflow,tool,status}`                  |
|               | è°ƒç”¨è€—æ—¶   | `tool_latency_seconds{workflow,tool}`                     |

**åˆå§‹åŒ–æ–¹å¼**:

åœ¨æœåŠ¡å¯åŠ¨æ—¶(api-gateway / job-worker)æ³¨å†Œå…¨å±€å›è°ƒ:

```go
import einoobs "z-novel-ai-api/internal/observability/eino"

func main() {
    einoobs.InitGlobalCallbacks()  // æ³¨å†ŒEinoå…¨å±€å›è°ƒ
    // ...
}
```

**é“¾è·¯è¿½è¸ª**:

- é›†æˆ OpenTelemetry,æ¯æ¬¡ LLM è°ƒç”¨è‡ªåŠ¨åˆ›å»º Span
- åŒ…å«å…³é”®å±æ€§:`llm.provider`ã€`llm.model`ã€`llm.prompt_tokens`ç­‰

---

## 4. ä¸‰å¤§ AI ç”Ÿæˆå™¨

### 4.1 ProjectCreationGenerator (é¡¹ç›®å­µåŒ–ç”Ÿæˆå™¨)

**ä½ç½®**: `internal/application/story/project_creation_generator.go`

**åœºæ™¯**: é€šè¿‡ 4 é˜¶æ®µå¯¹è¯å°†ç”¨æˆ·çš„æ¨¡ç³Šæƒ³æ³•è½¬åŒ–ä¸ºæ­£å¼é¡¹ç›®ã€‚

**ç¼–æ’æ¨¡å¼**: **Chain**(é¡ºåºæµæ°´çº¿)

**æ ¸å¿ƒæµç¨‹**:

```mermaid
flowchart LR
    Input[ç”¨æˆ·è¾“å…¥+é˜¶æ®µ+è‰ç¨¿] --> BuildVars[æ„å»ºæ¨¡æ¿å˜é‡]
    BuildVars --> ChatTemplate[æ ¼å¼åŒ–Messages]
    ChatTemplate --> LLM[LLM.Generate<br/>+JSON Schema]
    LLM --> Parse[è§£æJSONä¿¡å°]
    Parse --> Validate[ä¸šåŠ¡æ ¡éªŒ]
    Validate --> Output[è¿”å›Stage/Draft/Action]

    LLM -.ä¸æ”¯æŒSchema.-> Fallback[é™çº§ä¸ºPrompt-only]
```

**è¾“å…¥ç»“æ„**:

```go
type ProjectCreationGenerateInput struct {
    Stage       string           // å½“å‰é˜¶æ®µ: discover/narrow/draft/confirm
    Draft       json.RawMessage  // å½“å‰è‰ç¨¿çŠ¶æ€
    Prompt      string           // ç”¨æˆ·è¾“å…¥
    Attachments []TextAttachment // é™„ä»¶(å‚è€ƒææ–™)
    Provider    string           // æŒ‡å®šProvider(å¯é€‰)
    Model       string           // æŒ‡å®šæ¨¡å‹(å¯é€‰)
}
```

**è¾“å‡ºç»“æ„**:

```go
type ProjectCreationGenerateOutput struct {
    AssistantMessage     string                       // AIå›å¤æ–‡æœ¬
    NextStage            string                       // ä¸‹ä¸€é˜¶æ®µ
    Draft                json.RawMessage              // æ›´æ–°åçš„è‰ç¨¿
    Action               string                       // åŠ¨ä½œç±»å‹: continue/create_project
    RequiresConfirmation bool                         // æ˜¯å¦éœ€è¦ç”¨æˆ·ç¡®è®¤
    ProposedProject      *ProjectCreationProjectDraft // æ‹Ÿåˆ›å»ºçš„é¡¹ç›®ä¿¡æ¯
    Meta                 LLMUsageMeta                 // å…ƒä¿¡æ¯(Token/Modelç­‰)
}
```

**å®‰å…¨é—¨æ§**:

ä¸ºé¿å…æ¨¡å‹å¹»è§‰å¯¼è‡´è¯¯åˆ›å»ºé¡¹ç›®,æœåŠ¡ç«¯å¢åŠ ç¡®å®šæ€§é—¨æ§:

1. å¿…é¡»å¤„äº`confirm`é˜¶æ®µ
2. å¿…é¡»ä»ç”¨æˆ·è¾“å…¥ä¸­æ£€æµ‹åˆ°æ˜ç¡®ç¡®è®¤æ„å›¾(æ£€æµ‹å¦å®šè¯ä¼˜å…ˆæ‹¦æˆª)
3. å³ä½¿æ¨¡å‹è¾“å‡º`create_project`ä¹Ÿä¸æ‰§è¡Œ,æ”¹ä¸ºç»§ç»­è¦æ±‚ç¡®è®¤

---

### 4.2 FoundationGenerator (ä¸€æ½å­ç”Ÿæˆå™¨)

**ä½ç½®**: `internal/application/story/foundation_generator.go`

**åœºæ™¯**: é¡¹ç›®å†·å¯åŠ¨æ—¶,ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´è®¾å®šåŒ…(ä¸–ç•Œè§‚+è§’è‰²+å¤§çº²)ã€‚

**ç¼–æ’æ¨¡å¼**: **Chain**(é¡ºåºæµæ°´çº¿)

**æ ¸å¿ƒæµç¨‹**:

```mermaid
flowchart LR
    Input[é¡¹ç›®ä¿¡æ¯+Prompt] --> ChatTemplate[æ ¼å¼åŒ–Messages]
    ChatTemplate --> LLM[LLM.Generate<br/>+JSON Schema]
    LLM --> Parse[æå–JSONå¯¹è±¡]
    Parse --> Decode[ååºåˆ—åŒ–ä¸ºPlan]
    Decode --> Output[FoundationPlan]

    LLM -.ä¸æ”¯æŒSchema.-> Fallback[é™çº§Prompt-only]
    Parse -.JSONä¸å®Œæ•´.-> Extract[æ­£åˆ™æå–]
```

**è¾“å‡ºç»“æ„ (FoundationPlan)**:

```go
type FoundationPlan struct {
    NovelFoundation NovelFoundation  // å°è¯´åŸºåº•(æ ‡é¢˜+ç®€ä»‹)
    Worldview       Worldview        // ä¸–ç•Œè§‚
    Characters      []Character      // è§’è‰²åˆ—è¡¨
    Relations       []CharacterRelation  // è§’è‰²å…³ç³»
    Volumes         []Volume         // å·åˆ—è¡¨
    Chapters        []Chapter        // ç« èŠ‚åˆ—è¡¨(å«å¤§çº²)
}
```

**æµå¼æ”¯æŒ**:

```go
// æ”¯æŒSSEæµå¼è¿”å›
func (g *FoundationGenerator) Stream(ctx, input) (*schema.StreamReader[*schema.Message], error)
```

**å¹‚ç­‰åº”ç”¨**:

- `POST /v1/projects/:pid/foundation/apply`æ¥æ”¶ Plan å¹¶è½åº“
- æŒ‰`ai_key`åš Upsert,æ”¯æŒé‡å¤è°ƒç”¨

---

### 4.3 ArtifactGenerator (è®¾å®šè¿­ä»£ç”Ÿæˆå™¨)

**ä½ç½®**: `internal/application/story/artifact_generator.go`

**åœºæ™¯**: åœ¨å·²æœ‰é¡¹ç›®ä¸Šé€šè¿‡é•¿æœŸä¼šè¯åå¤æ‰“ç£¨å•ä¸ªè®¾å®šç±»å‹(ä¸–ç•Œè§‚/è§’è‰²/å¤§çº²)ã€‚

**ç¼–æ’æ¨¡å¼**: **Graph + ToolCalling** (ReAct å›è·¯)

**æ ¸å¿ƒæµç¨‹**:

```mermaid
flowchart TD
    Input([è¾“å…¥+ä»»åŠ¡ç±»å‹]) --> Init[åˆå§‹åŒ–State+Messages]
    Init --> LLM[LLM.Generate<br/>æ”¯æŒToolCalling]
    LLM --> HasTools{æ˜¯å¦æœ‰tool_calls?}
    HasTools -->|æ˜¯| ToolsNode[ToolsNode.Invoke]
    ToolsNode --> Rounds{è¾¾åˆ°æœ€å¤§è½®æ¬¡?}
    Rounds -->|å¦| LLM
    Rounds -->|æ˜¯| Error[è¿”å›é”™è¯¯]
    HasTools -->|å¦| Parse[è§£æJSON]
    Parse --> Validate[ä¸šåŠ¡æ ¡éªŒ]
    Validate --> Output([è¾“å‡ºArtifact])

    LLM -.ä¸æ”¯æŒTools.-> Fallback[é™çº§ä¸ºæ— å·¥å…·æ¨¡å¼]
```

**Tool é›†(ä¸€æœŸ)**:

| Tool åç§°             | åŠŸèƒ½                       | ç¤ºä¾‹                                    |
| --------------------- | -------------------------- | --------------------------------------- |
| `artifact_get_active` | è·å–æŒ‡å®šç±»å‹çš„å½“å‰æ¿€æ´»è®¾å®š | `artifact_get_active("worldview")`      |
| `artifact_search`     | åœ¨è®¾å®šä¸­åšå…³é”®è¯æ£€ç´¢       | `artifact_search("ä¸»è§’", "characters")` |
| `project_get_brief`   | è·å–é¡¹ç›®æ‘˜è¦ä¿¡æ¯           | `project_get_brief()`                   |

**å·¥å…·å®ç°** (`internal/application/story/artifact_tools.go`):

```go
// åªè¯»å·¥å…·,ä¸æ¥æ”¶tenant/projectå‚æ•°(ç”±ä¸Šä¸‹æ–‡æ³¨å…¥)
func makeArtifactToolGetActive(currentWorldview, currentCharacters, currentOutline json.RawMessage) einotool.InvokableTool
func makeArtifactToolSearch(currentWorldview, currentCharacters, currentOutline json.RawMessage) einotool.InvokableTool
func makeProjectGetBriefTool(projectTitle, projectDescription string) einotool.InvokableTool
```

**é™çº§ç­–ç•¥**:

- ä¸æ”¯æŒ ToolCalling çš„ Provider è‡ªåŠ¨åˆ‡æ¢ä¸º"æ— å·¥å…·æ¨¡å¼"
- æœ€å¤§å·¥å…·è½®æ¬¡é™åˆ¶(é»˜è®¤ 5 è½®),é¿å…æˆæœ¬å¤±æ§

---

## 5. æ•°æ®æµå‘ä¸è°ƒç”¨é“¾

### 5.1 å®Œæ•´è°ƒç”¨é“¾ç¤ºä¾‹ (Artifact ç”Ÿæˆ)

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant H as ConversationHandler
    participant AG as ArtifactGenerator
    participant PR as PromptRegistry
    participant LF as EinoFactory
    participant M as ChatModel
    participant TN as ToolsNode
    participant CB as Callbacks

    U->>H: POST /v1/projects/:pid/sessions/:sid/messages
    H->>H: åŠ è½½å½“å‰æ¿€æ´»ç‰ˆæœ¬è®¾å®š
    H->>AG: Generate(input)
    AG->>PR: ChatTemplate("artifact_v1")
    PR-->>AG: æ¨¡æ¿
    AG->>LF: Get(provider)
    LF-->>AG: ChatModel
    AG->>AG: buildGraph(ctx)
    AG->>M: Generate(messages, tools, options)
    M-->>CB: OnStart
    M-->>AG: AssistantMessage(tool_calls)
    AG->>TN: Invoke(tool_calls)
    TN-->>CB: Tool OnStart
    TN->>TN: artifact_get_active("worldview")
    TN-->>AG: ToolMessage(result)
    TN-->>CB: Tool OnEnd
    AG->>M: Generate(updated_messages, tools)
    M-->>AG: AssistantMessage(content)
    M-->>CB: OnEnd
    AG->>AG: Parse+Validate
    AG-->>H: ArtifactGenerateOutput
    H->>H: åˆ›å»ºæ–°ç‰ˆæœ¬å…¥åº“
    H-->>U: HTTP 200 + new_version
```

---

## 6. HTTP API æ¥å£

### 6.1 é¡¹ç›®å­µåŒ– (ProjectCreation)

| æ¥å£                                          | æ–¹æ³• | æè¿°             |
| --------------------------------------------- | ---- | ---------------- |
| `/v1/project-creation-sessions`               | POST | åˆ›å»ºå­µåŒ–ä¼šè¯     |
| `/v1/project-creation-sessions/:sid/messages` | POST | å‘é€å¯¹è¯æŒ‡ä»¤     |
| `/v1/project-creation-sessions/:sid`          | GET  | è·å–ä¼šè¯çŠ¶æ€     |
| `/v1/project-creation-sessions/:sid/turns`    | GET  | è·å–å¯¹è¯è½®æ¬¡å†å² |

**è¯·æ±‚ç¤ºä¾‹**:

```bash
# åˆ›å»ºä¼šè¯
curl -X POST http://localhost:8080/v1/project-creation-sessions \
  -H "X-Tenant-ID: tenant-123" \
  -H "Authorization: Bearer xxx" \
  -H "Content-Type: application/json"

# å‘é€å¯¹è¯
curl -X POST http://localhost:8080/v1/project-creation-sessions/sess-abc/messages \
  -H "Content-Type: application/json" \
  -d '{
    "content": "æˆ‘æƒ³å†™ä¸€ä¸ªç§‘å¹»å°è¯´"
  }'
```

---

### 6.2 è®¾å®šè¿­ä»£ (é•¿æœŸä¼šè¯)

| æ¥å£                                        | æ–¹æ³• | æè¿°                         |
| ------------------------------------------- | ---- | ---------------------------- |
| `/v1/projects/:pid/sessions`                | POST | åˆ›å»ºé•¿æœŸä¼šè¯                 |
| `/v1/projects/:pid/sessions/:sid/messages`  | POST | å‘é€ä»»åŠ¡æŒ‡ä»¤(æŒ‡å®š task_type) |
| `/v1/projects/:pid/artifacts`               | GET  | è·å–æ„ä»¶åˆ—è¡¨                 |
| `/v1/projects/:pid/artifacts/:aid/versions` | GET  | è·å–ç‰ˆæœ¬åˆ—è¡¨                 |
| `/v1/projects/:pid/artifacts/:aid/rollback` | POST | å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬               |

**ä»»åŠ¡ç±»å‹(task_type)**:

- `novel_foundation`: å°è¯´åŸºåº•(æ ‡é¢˜+ç®€ä»‹)
- `worldview`: ä¸–ç•Œè§‚è®¾å®š
- `characters`: è§’è‰²ä¸å…³ç³»ç½‘ç»œ
- `outline`: å·ç« å¤§çº²

**è¯·æ±‚ç¤ºä¾‹**:

```bash
# å‘é€ä»»åŠ¡æŒ‡ä»¤
curl -X POST http://localhost:8080/v1/projects/proj-123/sessions/sess-456/messages \
  -H "Content-Type: application/json" \
  -d '{
    "content": "ç”Ÿæˆä¸€ä¸ªèµ›åšæœ‹å…‹é£æ ¼çš„ä¸–ç•Œè§‚",
    "task_type": "worldview"
  }'

# å›æ»šç‰ˆæœ¬
curl -X POST http://localhost:8080/v1/projects/proj-123/artifacts/art-789/rollback \
  -H "Content-Type: application/json" \
  -d '{
    "target_version_id": "v-001"
  }'
```

---

### 6.3 ä¸€æ½å­ç”Ÿæˆ (Foundation)

| æ¥å£                                    | æ–¹æ³•     | æè¿°                  |
| --------------------------------------- | -------- | --------------------- |
| `/v1/projects/:pid/foundation/preview`  | POST     | åŒæ­¥é¢„è§ˆç”Ÿæˆ Plan     |
| `/v1/projects/:pid/foundation/stream`   | GET/POST | SSE æµå¼ç”Ÿæˆ          |
| `/v1/projects/:pid/foundation/generate` | POST     | å¼‚æ­¥ç”Ÿæˆ(è¿”å› Job ID) |
| `/v1/projects/:pid/foundation/apply`    | POST     | å°† Plan è½åº“          |

**è¯·æ±‚ç¤ºä¾‹**:

```bash
# åŒæ­¥ç”Ÿæˆé¢„è§ˆ
curl -X POST http://localhost:8080/v1/projects/proj-123/foundation/preview \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "ä¸€ä¸ªå…³äºæ—¶é—´æ—…è¡Œçš„ç§‘å¹»æ•…äº‹",
    "target_word_count": 100000
  }'

# åº”ç”¨Plan
curl -X POST http://localhost:8080/v1/projects/proj-123/foundation/apply \
  -H "Content-Type: application/json" \
  -H "Idempotency-Key: unique-key-123" \
  -d '{
    "plan": { ... }  # ä»previewè¿”å›çš„Plan
  }'
```

---

## 7. é…ç½®ä¸éƒ¨ç½²

### 7.1 ç¯å¢ƒå˜é‡é…ç½®

```bash
# LLM Provideré…ç½®
LLM_DEFAULT_PROVIDER=openai
LLM_PROVIDERS_OPENAI_API_KEY=sk-xxx
LLM_PROVIDERS_OPENAI_BASE_URL=https://api.openai.com/v1
LLM_PROVIDERS_OPENAI_MODEL=gpt-4o
LLM_PROVIDERS_OPENAI_MAX_TOKENS=8000
LLM_PROVIDERS_OPENAI_TEMPERATURE=0.7

# å¤‡ç”¨Provider
LLM_PROVIDERS_DEEPSEEK_API_KEY=sk-yyy
LLM_PROVIDERS_DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
LLM_PROVIDERS_DEEPSEEK_MODEL=deepseek-chat
```

### 7.2 æœ¬åœ°è¿è¡Œ

```bash
# å¯åŠ¨ä¾èµ–æœåŠ¡
docker compose up -d

# æ•°æ®åº“è¿ç§»
make migrate-up

# å¯åŠ¨APIç½‘å…³(é»˜è®¤FEATURES_CORE_ENABLED=false,ä¸ä¾èµ–gRPCæœåŠ¡)
JWT_SECRET="dev-secret" \
FEATURES_CORE_ENABLED=false \
go run ./cmd/api-gateway
```

### 7.3 Docker éƒ¨ç½²

```yaml
# docker-compose.yaml (LLMç›¸å…³éƒ¨åˆ†)
services:
  api-gateway:
    environment:
      - LLM_DEFAULT_PROVIDER=openai
      - LLM_PROVIDERS_OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_PROVIDERS_OPENAI_MODEL=gpt-4o
```

---

## 8. æœªæ¥è§„åˆ’

### 8.1 çŸ­æœŸè§„åˆ’ (Milestone 3)

- [ ] **å¢é‡ Patch æ¨¡å¼**: æ”¯æŒ AI ä»…è¾“å‡º`JSON Patch`,å‡å°‘ Token æ¶ˆè€—
- [ ] **ä¸Šä¸‹æ–‡è‡ªåŠ¨æ‘˜è¦**: é•¿ä¼šè¯è¶…è¿‡é˜ˆå€¼æ—¶è‡ªåŠ¨å‹ç¼©å†å²
- [ ] **æ ¡éªŒå¤±è´¥ä¿®å¤å›è·¯**: Graph å†… Validate â†’ Repair â†’ Re-run

### 8.2 ä¸­æœŸè§„åˆ’ (Milestone 4)

- [ ] **è®¾å®šå†²çªæ‰«æ**: æ£€æµ‹æ–°ç”Ÿæˆå†…å®¹ä¸å·²æœ‰è®¾å®šçš„çŸ›ç›¾
- [ ] **å¤šåˆ†æ”¯åˆ›ä½œ**: æ”¯æŒåŒä¸€èŠ‚ç‚¹çš„ A/B ç‰ˆæœ¬å¹¶è¡Œä¸å¯¹æ¯”
- [ ] **å®Œæ•´ RAG æ£€ç´¢**: Milvus å‘é‡æ£€ç´¢ä¸ä¸Šä¸‹æ–‡å¬å›

### 8.3 é•¿æœŸè§„åˆ’ (Milestone 5)

- [ ] **ç« èŠ‚ç”Ÿæˆé—­ç¯**: è¡¥é½ç« èŠ‚æ­£æ–‡çš„åŒæ­¥/SSE/å¼‚æ­¥è·¯å¾„
- [ ] **Tool å‡çº§ä¸º RAG**: `artifact_search`ä»å­—ç¬¦ä¸²åŒ¹é…å‡çº§ä¸ºå‘é‡å¬å›
- [ ] **å¤šæ¨¡æ€æ”¯æŒ**: æ”¯æŒå›¾ç‰‡å‚è€ƒææ–™è¾“å…¥

---

## é™„å½•

### A. ç›¸å…³æ–‡æ¡£ç´¢å¼•

| æ–‡æ¡£             | è·¯å¾„                                      | æè¿°                             |
| ---------------- | ----------------------------------------- | -------------------------------- |
| Eino ç¼–æ’è®¾è®¡    | `docs/10-Einoç¼–æ’ä¸å·¥ä½œæµè®¾è®¡.md`         | Eino æ¡†æ¶é›†æˆè§„èŒƒ                |
| è®¾å®šç”Ÿæˆé‡æ„     | `docs/22-Einoè®¾å®šç”Ÿæˆå·¥ä½œæµé‡æ„è®¾è®¡.md`   | Chain/Graph/ToolCalling å‡çº§è®°å½• |
| å¯¹è¯é©±åŠ¨æŠ€æœ¯è§„èŒƒ | `docs/21-å¯¹è¯é©±åŠ¨å°è¯´ç”Ÿæˆä¸€æœŸå®æ–½è®°å½•.md` | å®Œæ•´æŠ€æœ¯è§„èŒƒä¸å®æ–½è®°å½•           |
| é¡¹ç›®æ¦‚è§ˆ         | `CLAUDE.md`                               | é¡¹ç›®å½“å‰çŠ¶æ€ä¸ç›®å½•ç»“æ„           |

### B. å…³é”®ä»£ç å…¥å£

| æ¨¡å—                   | æ–‡ä»¶è·¯å¾„                                                   |
| ---------------------- | ---------------------------------------------------------- |
| LLM å·¥å‚               | `internal/infrastructure/llm/eino_factory.go`              |
| ProjectCreation ç”Ÿæˆå™¨ | `internal/application/story/project_creation_generator.go` |
| Foundation ç”Ÿæˆå™¨      | `internal/application/story/foundation_generator.go`       |
| Artifact ç”Ÿæˆå™¨        | `internal/application/story/artifact_generator.go`         |
| Artifact å·¥å…·é›†        | `internal/application/story/artifact_tools.go`             |
| Prompt æ³¨å†Œè¡¨          | `internal/workflow/prompt/registry.go`                     |
| Eino å¯è§‚æµ‹æ€§          | `internal/observability/eino/handler.go`                   |

### C. æœ¯è¯­è¡¨

| æœ¯è¯­                | è§£é‡Š                                        |
| ------------------- | ------------------------------------------- |
| **Artifact**        | æ„ä»¶,æŒ‡ä¸–ç•Œè§‚/è§’è‰²/å¤§çº²ç­‰å¯ç‰ˆæœ¬åŒ–çš„è®¾å®šèµ„äº§ |
| **Foundation**      | å°è¯´åŸºåº•,åŒ…å«å®Œæ•´è®¾å®šåŒ…(ä¸–ç•Œè§‚+è§’è‰²+å¤§çº²)   |
| **ProjectCreation** | é¡¹ç›®å­µåŒ–,é€šè¿‡å¯¹è¯å¼•å¯¼åˆ›å»ºé¡¹ç›®               |
| **Chain**           | Eino é¡ºåºæµæ°´çº¿,é€‚åˆçº¿æ€§æµç¨‹                |
| **Graph**           | Eino æœ‰å‘å›¾ç¼–æ’,æ”¯æŒåˆ†æ”¯ä¸å›è·¯              |
| **ToolCalling**     | LLM ä¸»åŠ¨è°ƒç”¨å·¥å…·è·å–æ•°æ®                    |
| **ReAct**           | Reasoning + Acting,å·¥å…·è°ƒç”¨å›è·¯æ¨¡å¼         |
| **ai_key**          | AI ç”Ÿæˆå†…å®¹çš„ç¨³å®šæ ‡è¯†ç¬¦,ç”¨äºç²¾å‡†åŒ¹é…æ›´æ–°    |

---

**æ–‡æ¡£ç»´æŠ¤**: æœ¬æ–‡æ¡£éšé¡¹ç›®æ¼”è¿›æŒç»­æ›´æ–°,å¦‚æœ‰ç–‘é—®è¯·å‚è€ƒæºç æˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚
