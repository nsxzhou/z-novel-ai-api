# configs/config.yaml
# AI 小说生成后端主配置文件

app:
  name: "z-novel-ai-api"
  version: "${VERSION:v0.0.0}"
  env: "${APP_ENV:development}"

server:
  http:
    host: "0.0.0.0"
    port: ${HTTP_PORT:8080}
    read_timeout: 30s
    write_timeout: 60s
    idle_timeout: 120s
  grpc:
    host: "0.0.0.0"
    port: ${GRPC_PORT:50051}
    max_recv_msg_size: 16777216 # 16MB
    max_send_msg_size: 16777216

clients:
  grpc:
    dial_timeout: 3s
    retrieval_service_addr: "${RETRIEVAL_GRPC_ADDR:localhost:50052}"
    story_gen_service_addr: "${STORY_GEN_GRPC_ADDR:localhost:50053}"
    memory_service_addr: "${MEMORY_GRPC_ADDR:localhost:50054}"
    validator_service_addr: "${VALIDATOR_GRPC_ADDR:localhost:50055}"

database:
  postgres:
    host: "${DB_HOST:localhost}"
    port: ${DB_PORT:5432}
    user: "${DB_USER:postgres}"
    password: "${DB_PASSWORD}" # 通过 Vault 注入
    database: "${DB_NAME:z_novel_ai}"
    ssl_mode: "disable"
    max_open_conns: 50
    max_idle_conns: 10
    conn_max_lifetime: 30m
    conn_max_idle_time: 5m

cache:
  redis:
    host: "${REDIS_HOST:localhost}"
    port: ${REDIS_PORT:6379}
    password: "${REDIS_PASSWORD}" # 通过 Vault 注入
    db: 0
    pool_size: 100
    min_idle_conns: 10
    dial_timeout: 5s
    read_timeout: 3s
    write_timeout: 3s

vector:
  milvus:
    host: "${MILVUS_HOST:localhost}"
    port: ${MILVUS_PORT:19530}
    user: "${MILVUS_USER}"
    password: "${MILVUS_PASSWORD}" # 通过 Vault 注入
    collection_prefix: "z_novel"
    index_type: "HNSW"
    metric_type: "COSINE"
    hnsw_m: 16
    hnsw_ef_construction: 200

storage:
  r2:
    account_id: "${STORAGE_R2_ACCOUNT_ID:4faec3c14a0eb6dff1f8ae588218e1ee}"
    access_key_id: "${STORAGE_R2_ACCESS_KEY_ID}"
    secret_access_key: "${STORAGE_R2_SECRET_ACCESS_KEY}"
    bucket: "${STORAGE_R2_BUCKET:novel}"
    public_url: "${STORAGE_R2_PUBLIC_URL:https://pub-f5969c4787c14d70a203a5a8264bb457.r2.dev}"

llm:
  default_provider: "openai"
  providers:
    openai:
      api_key: "${OPENAI_API_KEY}" # 通过 Vault 注入
      base_url: "https://x666.me/v1"
      model: "gemini-3-flash-preview"
      max_tokens: 8192
      temperature: 0.7
      timeout: 120s
    deepseek:
      api_key: "${DEEPSEEK_API_KEY}" # 通过 Vault 注入
      base_url: "https://api.deepseek.com"
      model: "deepseek-chat"
      max_tokens: 8192
      temperature: 0.7
      timeout: 120s
    siliconflow:
      api_key: "${SILICONFLOW_API_KEY}"
      base_url: "https://api.siliconflow.cn/v1"
      model: "deepseek-ai/DeepSeek-V3"
      max_tokens: 4096
      temperature: 0.7
      timeout: 120s

embedding:
  provider: "openai" # 切换为通用 openai 格式
  model: "BAAI/bge-m3"
  dimension: 1024
  batch_size: 32
  endpoint: "http://localhost:8000"
  api_key: "${EMBEDDING_API_KEY}"

messaging:
  redis_stream:
    max_len: 100000
    consumer_group_prefix: "cg"
    block_timeout: 5s
    claim_interval: 30s
    retry_limit: 3
    retry_backoff:
      initial: 1s
      max: 60s
      multiplier: 2

observability:
  logging:
    level: "${LOG_LEVEL:info}"
    format: "json"
    output: "stdout"
  tracing:
    enabled: true
    exporter: "otlp"
    endpoint: "${OTLP_ENDPOINT:localhost:4317}"
    sample_rate: 1.0
  metrics:
    enabled: true
    port: ${METRICS_PORT:9464}
    path: "/metrics"

security:
  jwt:
    secret: "${JWT_SECRET}" # 通过 Vault 注入
    issuer: "z-novel-ai"
    expiration: 24h
    refresh_expiration: 168h # 7 days
  rate_limit:
    enabled: true
    requests_per_second: 100
    burst: 200
  cors:
    allowed_origins:
      - "*"
    allowed_methods:
      - "GET"
      - "POST"
      - "PUT"
      - "DELETE"
    allowed_headers:
      - "Authorization"
      - "Content-Type"
      - "X-Request-ID"
      - "Idempotency-Key"

features:
  validation:
    enabled: true
    default_pass_on_failure: true
  memory_writeback:
    enabled: true
    async: true
  core:
    enabled: false
